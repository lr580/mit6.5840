[mit6.5840网址](http://nil.csail.mit.edu/6.5840/2025/)

# 实现过程

## Lab1

### 环境准备

根据 [lab1](http://nil.csail.mit.edu/6.5840/2025/labs/lab-mr.html) 的第一句话，克隆远程仓库获取源码

```sh
git clone git://g.csail.mit.edu/6.5840-golabs-2025 6.5840
```

在 [setup go](http://nil.csail.mit.edu/6.5840/2025/labs/go.html)，需求 Go 1.22 版本，使用 `go version` 可查询版本。

需求使用 Linux，这里我使用 WSL2。按照指示检查运行：

> ```go
> cd src/main
> go build -buildmode=plugin ../mrapps/wc.go
> rm mr-out*
> go run mrsequential.go wc.so pg*.txt
> more mr-out-0
> ```

其中，build的构建模式为plugin，它生成`.so` 文件，即 `wc.go`，项目结构 `src/`

- `mrapps/` 是 map-reduce 实际应用例子，如 `wc.go`，看到它定义了 Map 和 Reduce 函数。其中 Map 函数的第一个参数在例子中忽略，只看第二个参数(文件内容)，它把不是 Letter(a-zA-Z) 的连续内容作为分隔符，然后分割后的单词数组返回 (`mr/KeyValue`) (没有做合并)。Reduce 函数，传入 key 值和 values 列表，values 长度转字符串作为该 key 的合并结果。
- 对 `main/mrsequential.go`，传入 `.so` 执行，选择文件名执行。它的 `loadPlugin` 函数，导入插件，查找 Map, Reduce 函数，并返回。对每一份文件，把读取的文件内容和文件名传入 map 函数，得到 key-value 列表；所有文件的合并到一个列表里。(实际上应该分快存储)，然后进行排序，创建输出文件。排序后 key 相同的全部 value 集合并到一个 string[] 里。把这个 slice 传给 reduce 函数，然后输出结果到文件。

> 注意：只要修改了项目任意代码，plugin 一定要重新编译。

### 任务描述

#### 任务

实现：协调节点coordinator, 工作节点worker。单协调进程，任意多个工作节点，该lab只考虑工作节点都在同一个机子。使用RPC，循环请求协调者执行任务。协调者应当注意若工作者在10秒内未能完成任务，将它分发给其他工作者。

`main/mrcoorinator.go`, `main/mrworker.go` 是给定不可修改的代码，参考它们，实现 `mr/coordinator.go`，`mr/worker.go`，`mr/rpc.go`。执行 mapreduce 的过程：

```sh
go run mrcoordinator.go pg-*.txt # 一个
go run mrworker.go wc.so # 一个或多个
cat mr-out-* | sort | more # 查看结果
```

使用测试脚本检查 `wc, indexer` 任务是否产出正确，以及测试是否并行，能否恢复crash。

```sh
bash test-mr.sh
```

把 `mr/coordinator.go` 的 Done 函数改为`ret := true`，让协调者马上退出。如果全部通过，测试完成。

若 rpc 报错如 ` method "Done" has 1 input parameters`，可以忽略，因为它不会被远程调用。[文档](https://golang.org/src/net/rpc/server.go) 帮助检查是否所有方法对 RPC 合适，即有 3 输入。若出现 `connect: connection refused`，当协调者关闭后，无法连接是正常的。

#### 规则

- map 阶段，分割中间 keys 为桶，给 `nReduce` 个任务，在 `main/mrcoordinator.go` 该参数传递给 `MakeCoordinator()`，每个 mapper 要创建 `nReduce` 个中间文件给 reduce 任务消费。
- 工作者实现第 X 个 reduce 任务时，写到 `mr-out-X`。该文件对每个 Reduce 函数输出包含一行，使用 format `%v %v` 生成 key value 行。查阅 `main/sequential.go` 查看格式范例。
- 工作者把中间 Map 输出放当前工作目录。
- `main/mrcoordinator.go` 期望 `mr/coordinator.go` 实现 `Done()` 方法，返回 true 如果任务执行完毕，随后 `mrcoordinator.go` 退出。
- 全部任务完成，工作者进程关闭，可以用 `call()` 的返回值实现。若工作者无法联系协调者，可以假设任务完毕，并让工作者关闭。也可以自由发挥。

#### 提示

- 一个开始的办法是调整 `mr/worker.go` 的 `Worker()` 发送 RPC 给协调者请求任务，然后修改协调者回答未开始的map任务文件名，然后修改工作者去读取文件，调用 Map 函数。
- 使用 go plugin 加载 map, reduce 任务，`.so` 文件。如果修改 `mr/` 的内容，可能需要重新构造 `.so`。
- 工作者共享同一个文件系统。
- 中间文件可以命名为 `mr-X-Y`，分别表示 map, reduce 编号。
- map 任务需要存储中间键值对在文件，使其可以在 reduce 被读取，可以考虑 json 包，参考示例代码读写。
- 可以使用 `ihash(key)` 函数(`worker.go`)选择reduce任务。
- 读文件，排序，存储reduce输出，可以参考 `mrsequential.go`。
- 协调者并发，需要锁住共享数据。
- 使用 Go race detector，如 `go run -race`。在 `test-mr.sh` 开头有注释，提示如何使用。
- 工作者有时需要等待，如 reduce 需要等最后一个 map 完成。可以周期轮询+sleep；或者 RPC 做一个等待循环，sync.Cond。每个 RPC handler 独立线程，所以 handler 等待不会阻止协调者处理其他 RPC。
- 协调者无法区分崩掉的、静止的、太慢的工作者。只能让协调者等待一段时间，然后切换工作者。
- 若实现文章 Section 3.6 的 Backup 任务，它只应当长时间后才被安排，如10s，也就是有挂掉的。
- 测试 crash，可以尝试 `mrapps/crash.go`，它随机关闭 map/reduce 函数。
- 防止 crash 导致写了一半的文件，MapReduce 论文使用 trick：使用临时文件，并原子地重命名它，如果完成了写。使用 `ioutil.TempFile / os.CreateTemp` 来创建这样的文件，然后 `os.Rename` 原子重命名。
- `test-mr.sh` 运行所有进程在 `mr-tmp`，如果挂了，中间过程在该文件找。
- `test-mr-many.sh` 运行多次，可以发现低概率错误。参数：运行次数。不要通过自己跑多次 `test-nr.sh` 来做它，这样协调者会复用一个 socket。
- Go RPC 只发送大写结构体字段，子结构体也是如此。
- 调用 RPC `call()`，返回结构体要所有字段赋值为默认值，有参见例子。否则，可能结果不对。

#### 通用提示

[url](http://nil.csail.mit.edu/6.5840/2025/labs/guidance.html)：

- Easy：数小时；Moderate：6h每周；hard：超过6h每周。

  大部分任务只需要几百行代码，但概念+debug困难。

- 在线 Go 教程 [here](http://tour.golang.org/)，[Effective Go](https://golang.org/doc/effective_go.html)，[Editor](https://golang.org/doc/editors.html)

- [race detector](https://blog.golang.org/race-detector) 报告的 race 需要修复。

- [Raft](https://thesquareplanet.com/blog/students-guide-to-raft/) 指引

- [locking](http://nil.csail.mit.edu/6.5840/2025/labs/raft-locking.txt) 指引

- [Raft structuring](http://nil.csail.mit.edu/6.5840/2025/labs/raft-structure.txt) 指引

- [图解Raft交互](http://nil.csail.mit.edu/6.5840/2025/notes/raft_diagram.pdf)

- 在每个节点收发消息关键位置 print，日志重定向到文件来分析，方便 debug

  结构化 debug 输出信息，那么 grep 查找消息更方便

- `DPrintf` 比 `log.Printf` 更有用

- [Go format strings](https://golang.org/pkg/fmt/)

- 颜色 / 列来解析 log 输出 [参考](https://blog.josejg.com/debugging-pretty/)

- git 教程 [url](https://git-scm.com/book/en/v2) [url2](https://www.kernel.org/pub/software/scm/git/docs/user-manual.html)

#### 调试技巧

先对问题的潜在成因提出假设；收集可能相关的证据；综合分析已获取的信息；根据需要重复上述过程。对于长时间的调试任务，建议做好记录

一种有效策略是逐步定位问题首次出现的时间节点。可以在程序执行的不同阶段插入状态检查代码，或是添加输出关键状态信息的日志语句，将日志保存至文件后仔细排查首个出现异常的时间点

Raft实验涉及的事件（如RPC请求到达、超时触发、节点故障）可能在意料之外的时刻发生，或以难以预料的顺序交错出现。例如某个节点刚决定参与竞选，而另一个节点却认为自己是当前领导者。建议推演"后续可能发生的情况"：比如当Raft代码释放互斥锁后，下一瞬间可能就会处理到达的RPC请求或超时事件。可通过打印语句来捕获实际的事件执行顺序。

必须严格遵循Raft论文图2的规范，容易遗漏其中规定的状态检查条件或必须执行的状态变更。若出现故障，请重新核验代码是否完全符合图2要求。

在编写代码时（即出现故障前），建议对代码依赖的前提条件添加显式检查（例如使用Go的[panic](https://gobyexample.com/panic)机制）。这类检查有助于发现后续代码无意中违背假设的情况。

若原本正常的代码出现异常，很可能是近期修改引入的问题。

故障往往藏在你最后检查的地方，因此即使对确信无误的代码也需保持审视

#### 挑战任务

- 实现自己的 MapReduce 任务，可以看 `mrapps/*` 例子，如文章 Section 2.3 的分布式 Grep。
- 让协调者，工作者在不同机器上工作，设置 RPC 在 TCP/IP 而不是 Unix sockets (参考注释 `Coordinator.server()`)，用共享文件系统读写文件。如 `ssh` 多个 [Athena cluster](http://kb.mit.edu/confluence/display/istcontrib/Getting+Started+with+Athena)，使用 [AFS](http://kb.mit.edu/confluence/display/istcontrib/AFS+at+MIT+-+An+Introduction) 共享文件，或自己用 AWS 实例 / S3 存储。

#### 代码梳理

`main/mrcoordinator.go` main 函数，把命令行参数全部传进去，以及 nReduce=10，执行 `mr.MakeCoordinator`，完毕 sleep 1s，返回值为 m，若 `m.Done()` 是 false，就一直 sleep 1s (轮询)。

`main/mrworker.go` main 函数，对 CLI 参数加载 plugin，调用 `mr.Worker` 执行 map, reduce。

`mr/rpc.go` 给定例子使用 RPC，对该例子，`mr/coordinator.go` 定义了 Example 函数，`mr/worker.go` 定义了 `CallExample()` 函数。在 `mr/worker.go` 定义了 call 函数，在 `mr/coordinator.go` 定义了 `server()` 结构体方法，用来执行 RPC。

`mr/worker.go` 定义了 ihash 函数用于字符串转 int。定义了 `KeyValue` 结构体。定义了 `Worker` 函数需要自己实现。

`mr/coordinator.go` 定义了 `Coordinator` 结构体及其成员方法(需要自己补充成员属性)。需要实现：①MakeCoordinator构造函数；②Done成员函数。

### 实现思路

具体细节见 `mr/worker.go`, `mr/coordinator.go`。分为多个部分描述：

#### coordinator.go

##### 构造函数

没有指定 map 任务数，故：按照文件数量分配 map 数量，一个文件一个 map。不考虑更加复杂的情况。

每个任务有两个属性：状态（空闲、运行中、完毕）、开始时间。构造两个任务列表，分别表示 map, reduce。

此外，给自己构造三个阶段：map 阶段，reduce 阶段，退出阶段。

##### 超时检测

10秒算超时。构造阶段设置一个 `deadWorkerChecker` 进程，隔段时间(如1s或5s)检测一次全体任务。对超时任务，直接重新设置为 IDLE。

*理由：如果后面发现 worker 没挂，让该任务被执行多次，因幂等不影响结果。可以给读写同一文件的过程加锁，避免 reducer 执行读到一半被覆盖*

由于超时检测会修改任务，而正常执行也会，避免竞态，在修改任务时加 mutex 锁

##### 分配任务

定义 Allocate RPC方法，对 worker 发送的请求，分配任务给 worker。

- 如果当前是退出阶段，发送信息给 worker 报告它退出。

- 否则，对当前任务列表(根据阶段选择 map 列表或 reduce 列表)，找到任意一个空闲任务分配给 worker

  简单起见，直接暴力遍历查找。后续需要的话可以用 bitset / map 等优化。

- 如果没有空闲任务，证明当前全部 map / reduce 都在执行，让 worker 继续等待。

加 mutex，下面结果收集同理。也是防止多个 RPC 竞态，不只是和 `deadWorkerChecker`。

##### 结果收集

定义 Report RPC方法，worker 完成任务后调用

- 如果当前状态和 worker 汇报的状态不一样，taskid 无意义，丢弃该饭会报错并告诉 worker。这证明 worker 挂掉了导致一个任务被执行多次。
- 否则，如果当前任务状态不是 RUNNING，报错。
- 否则，记录当前任务完成，更改状态。如果当前任务都完成了，进入下一阶段。

#### worker.go

##### 文件I/O

按要求进行文件读写。

- 除了 map 必须返回完整 content 外；对 KV 的读写使用流。
- 写文件，先写到一个临时文件(随机创建到当前目录)，写完后原子重命名为目标文件。
- 读文件，由于写操作 os.Rename 原子，不需要对读加锁，不会出现读写竞态等问题。

##### 主循环

由于在 `main` 里，它直接启动 `mrWorker`，不能像 `mrcoordinator` 那样 Done 轮询来结束，所以需要 worker 自己控制是否结束。

在这里设计结束主循环的情况只有两种：在发送 Allocate 时返回报错(coordinator挂了)、或者返回已完成。

主循环为：

1. 发送 Allocate 调用

   - 如果结果是等待，随机等待一段时间。

     *也可以设计指数退避*，这里从简考虑。

   - 否则，如果是 mapping / reducing，分别执行 map/reduce 任务。

2. 根据执行结果，发送 Report 调用。

##### mapping

过程：

1. 读文件

2. 执行 mapf 函数，得到 KV 列表

3. 将 KV 按 ihash 分桶

4. 每个桶的 KV 子列表直接写入中间文件 `mr-X-Y`，

   > X 是当前 map 号，Y 是全体 [0, nReduce)。这里 X,Y 0-indexed

如果写入报错，返回执行失败，否则都返回执行成功。

##### reducing

过程：

1. 读所有 `mr-X-Y` 文件，其中 Y 是当前 reduce 号，X 是全体任意。

   > 修复了 bugs，注意一定要严格是 X,Y 是整数，测试过程存在 `mr-??-Y`，其中 `??` 是字符串。避免匹配失败报错。

2. 合并所有 KV，然后排序

3. 排序后，同 K 的 V 分组，传入 reducef，然后记录该组答案

4. 写入该 reduce 任务的结果到 `mr-out-Y`

如果读写报错，返回执行失败，否则都返回执行成功。

# 过程记录

- 2025/9/29 2h 阅读Lab1代码，学习go语法
- 2025/10/1 2h 阅读Lab1代码、要求与指示，学习go RPC等
- 2025/10/2 4h 设计Lab1代码，学习go语法、map-reduce流程等
- 2025/10/3 5h 完成Lab1代码，学习go语法，编码，debug，文档等